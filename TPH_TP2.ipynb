{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 - Web Scraping + Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJEMPLO 1: TRABAJAMOS CON SPACY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.- IMPORTAMOS LAS LIBRERIAS Y TEXTO A ANALIZAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy es una biblioteca de procesamiento de lenguaje natural (NLP) escrita en Python, diseñada para ser rápida, eficiente y fácil de usar. Se utiliza ampliamente en tareas relacionadas con el análisis y la comprensión del lenguaje humano.\n",
    "\n",
    "¿Para qué se usa spaCy?\n",
    "\n",
    "spaCy se usa para muchas tareas de NLP, como:\n",
    "\n",
    "Tokenización: Dividir el texto en palabras, frases, etc.\n",
    "\n",
    "Lematización: Reducir palabras a su forma base\n",
    "\n",
    "Etiquetado gramatical (POS tagging): Identificar sustantivos, verbos, adjetivos, etc.\n",
    "\n",
    "Reconocimiento de entidades nombradas (NER): Identificar nombres propios, organizaciones, fechas, etc.\n",
    "\n",
    "Análisis de dependencias: Entender la estructura gramatical de una oración\n",
    "\n",
    "Detección de similitud entre textos\n",
    "\n",
    "Extracción de información\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALAMOS LA LIBRERIA\n",
    "!pip install watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGAMOS LA LIBRERIA PARA PODER INVOCARLA\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAMOS ALGUNOS DATOS DE PYTHON\n",
    "# Significado:\n",
    "# -v: versión de Python\n",
    "# -d: fecha actual\n",
    "# -u: última fecha en que se actualizó el notebook\n",
    "# -t: hora actual\n",
    "%watermark -v -d -u -t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -v -p numpy,pandas,watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dxNf9vuHrqp7",
    "outputId": "62a21443-6a3c-480a-a944-c915c0be6276",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# INSTALAMOS LA LIBRERIA EN CASO QUE NO CONTEMOS CON ELLA EN NUESTRO ENTORNO DE TRABAJO\n",
    "# spacy: instala la biblioteca spaCy para procesamiento de lenguaje natural.\n",
    "# watermark: instala una herramienta útil para ver información del entorno (versiones de paquetes, entorno de Python, etc.).\n",
    "# -q: significa quiet, es decir, reduce la salida del terminal al mínimo (menos ruido visual al instalar).\n",
    "# !pip install spacy watermark -q\n",
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCURRIO UN CONFLICTO DE VERSIONES CON NUMPY CON LO CUAL TUVE QUE EJECUTAR ESTA SENTENCIA\n",
    "# !pip install \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4k2pDwBtjWy"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download es_core_news_lg: Le dice a spaCy que descargue un modelo preentrenado de procesamiento de lenguaje natural (PLN).\n",
    "# es_core_news_lg: Es un modelo grande de spaCy entrenado para español:\n",
    "# es = español\n",
    "# core_news = texto de noticias, tipo de corpus con el que fue entrenado\n",
    "# lg = large (grande), lo que indica que es un modelo más preciso (pero más pesado que sm o md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download es_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XROdsYTwtyLp"
   },
   "outputs": [],
   "source": [
    "# PIPELINE DE SPACY\n",
    "# CARGAMOS EL MODELO\n",
    "import es_core_news_lg\n",
    "nlp = es_core_news_lg.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.- PRIMER TEXTO A ANALIZAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xo4mA7A4uUXN"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS UN TEXTO A PROCESAR \n",
    "texto_ejemplo = 'La inteligencia artificial es un campo de la ciencia relacionado con la creación de computadoras y máquinas que pueden razonar, aprender y actuar de una manera que normalmente requeriría inteligencia humana o que involucra datos cuya escala excede lo que los humanos pueden analizar.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptTnyA9FuyCF"
   },
   "outputs": [],
   "source": [
    "# PROCESAMOS EL TEXTO CON SPACY\n",
    "# nlp: Es el objeto del modelo (es_core_news_lg)\n",
    "# texto_ejemplo: Es un string de texto.\n",
    "# doc: Es el resultado del análisis. Un objeto tipo Doc de spaCy, que contiene tokens, etiquetas gramaticales, entidades nombradas, dependencias sintácticas, etc.\n",
    "doc = nlp(texto_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIRMAMOS QUE \"doc\" ES UN OBJETO SPACY\n",
    "print(type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAMOS EL CONTENIDO\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKPu-lHBvsfQ",
    "outputId": "da8d2518-208e-449f-e54a-53509401570a"
   },
   "outputs": [],
   "source": [
    "# PROCESO DE TOKENIZACION\n",
    "# RECORREMOS CON UN CICLO FOR EL TEXTO A PROCESAR CREANDO LA TOKENIZACIÓN DEL TEXTO EN CUESTION\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICAMOS QUE OBTUVIMOS UNA LISTA CON LOS TOKENS DEL TEXTO EN CUESTION\n",
    "print(type(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-3fvF7Lwl5x",
    "outputId": "640305cd-73db-45d2-bced-434ac5018ce5"
   },
   "outputs": [],
   "source": [
    "# PROCESO DE LEMATIZACIÓN\n",
    "# RECORREMOS LA LISTA ANTERIOR DE TOKENS PARA OBTENER LA LEMATIZACIÓN (FORMA BASE DE CADA TOKEN)\n",
    "for token in doc:\n",
    "    # SI EL VALOR QUE ESTAMOS ANALIZANDO NO ES PUNTUACION Y NO ES ESPACIO GENERAMOS EL LEMMA DE CADA PALABRA\n",
    "    if not token.is_punct and not token.is_space:\n",
    "        print(f\"'{token.text}' -> '{token.lemma_}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1lxtMfBXxgMl",
    "outputId": "53919f54-2fb2-4e3c-9794-6710410a5f11"
   },
   "outputs": [],
   "source": [
    "# PROCESO DE ETIQUETADO GRAMATICAL\n",
    "# token.text: El texto del token\n",
    "# token.pos_: la categoría gramatical general (ej: NOUN, VERB, ADJ...).\n",
    "# spacy.explain(token.pos_): Una descripción en texto de esa categoría.\n",
    "# token.tag_: La etiqueta gramatical más específica (usualmente basada en corpus de entrenamiento).\n",
    "for token in doc:\n",
    "    if not token.is_space: # IGNORAMOS LOS ESPACIOS QUE PUDIERAN PRESENTARSE\n",
    "        print(f\"'{token.text}' -> {token.pos_} ({spacy.explain(token.pos_)}) -> {token.tag_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rC2baEuzyduK",
    "outputId": "1fd4dc34-573f-4546-dbb1-8a9f71d3fd2f"
   },
   "outputs": [],
   "source": [
    "# PROCESO DE ANALISIS DE DEPENDENCIA SINTÁCTICA\n",
    "# token.text: El texto del token (palabra actual)\n",
    "# token.dep_: El tipo de dependencia gramatical (su función sintáctica en la oración: sujeto, objeto, raíz, etc.)\n",
    "# spacy.explain(token.dep_): Una breve explicación textual de esa dependencia\n",
    "# token.head.text: El término principal del que depende ese token (la \"cabeza sintáctica\")\n",
    "for token in doc:\n",
    "     if not token.is_space: # IGNORAMOS LOS ESPACIOS QUE PUDIERAN PRESENTARSE \n",
    "        print(f\"'{token.text}' -> {token.dep_} ({spacy.explain(token.dep_)}) -> '{token.head.text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "khIG9P4Oy06W",
    "outputId": "5ae60226-ca6a-4532-c27e-749e18e8a9ad"
   },
   "outputs": [],
   "source": [
    "# PROCESO DE VISUALIZACION DEL OBEJTO PROCESADO POR SPACY\n",
    "# displacy.render: función que dibuja una visualización del objeto doc (procesado por spaCy).\n",
    "# style='dep': indica que quieres ver el árbol de dependencias gramaticales (no entidades nombradas).\n",
    "# jupyter=True: le dice a spaCy que lo dibuje directamente dentro del notebook de Jupyter.\n",
    "# options={'distance': 120}: cambia la distancia horizontal entre palabras en el gráfico (para que sea más legible si la oración es larga).\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdCC4UHXzl5O",
    "outputId": "f0057dbf-55ce-4047-a162-6932bcf8d7f4"
   },
   "outputs": [],
   "source": [
    "# VISUALIZACION DE ENTIDADES\n",
    "# Las entidades nombradas son cosas como: personas, lugares, organizaciones, fechas, cantidades, etc.\n",
    "# ent.text: el texto de la entidad (ej. \"España\")\n",
    "# ent.label_: la etiqueta de tipo de entidad (ej. LOC)\n",
    "# spacy.explain(ent.label_): una descripción en texto del tipo (ej. \"Geopolitical entity\")\n",
    "if doc.ents:\n",
    "    print(\"Entidades encontradas:\")\n",
    "    print(\"Texto de la Entidad -> Etiqueta (Tipo)\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\"'{ent.text}' -> {ent.label_} ({spacy.explain(ent.label_)})\")\n",
    "else:\n",
    "    print(\"No se encontraron entidades nombradas en este texto.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "YiENpGV8z_lA",
    "outputId": "51b13385-7086-41eb-d057-f5d541f2fe16"
   },
   "outputs": [],
   "source": [
    "# VISUALIZACION DE ENTIDADES\n",
    "displacy.render(doc,style='ent',jupyter=True,options={'distance':200})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.- SEGUNDO TEXTO A ANALIZAR (CONTENIENDO ENTIDADES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINIMOS UN TEXTO A PROCESAR \n",
    "texto_ejemplo = '¿Quién liderará la tecnología del futuro: Estados Unidos o China? La especulación está en su punto máximo. La compañía de inteligencia artificial más famosa del mundo, OpenAI, es estadounidense. Los modelos producidos por DeepSeek, un competidor chino, son casi igual de buenos y más baratos.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESAMOS EL TEXTO CON SPACY\n",
    "# nlp: Es el objeto del modelo (es_core_news_lg)\n",
    "# texto_ejemplo: Es un string de texto.\n",
    "# doc: Es el resultado del análisis. Un objeto tipo Doc de spaCy, que contiene tokens, etiquetas gramaticales, entidades nombradas, dependencias sintácticas, etc.\n",
    "doc = nlp(texto_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIRMAMOS QUE \"doc\" ES UN OBJETO SPACY\n",
    "print(type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAMOS EL CONTENIDO\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESO DE TOKENIZACION\n",
    "# RECORREMOS CON UN CICLO FOR EL TEXTO A PROCESAR CREANDO LA TOKENIZACIÓN DEL TEXTO EN CUESTION\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICAMOS QUE OBTUVIMOS UNA LISTA CON LOS TOKENS DEL TEXTO EN CUESTION\n",
    "print(type(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESO DE LEMATIZACIÓN\n",
    "# RECORREMOS LA LISTA ANTERIOR DE TOKENS PARA OBTENER LA LEMATIZACIÓN (FORMA BASE DE CADA TOKEN)\n",
    "for token in doc:\n",
    "    # SI EL VALOR QUE ESTAMOS ANALIZANDO NO ES PUNTUACION Y NO ES ESPACIO GENERAMOS EL LEMMA DE CADA PALABRA\n",
    "    if not token.is_punct and not token.is_space:\n",
    "        print(f\"'{token.text}' -> '{token.lemma_}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESO DE ETIQUETADO GRAMATICAL\n",
    "# token.text: El texto del token\n",
    "# token.pos_: la categoría gramatical general (ej: NOUN, VERB, ADJ...).\n",
    "# spacy.explain(token.pos_): Una descripción en texto de esa categoría.\n",
    "# token.tag_: La etiqueta gramatical más específica (usualmente basada en corpus de entrenamiento).\n",
    "for token in doc:\n",
    "    if not token.is_space: # IGNORAMOS LOS ESPACIOS QUE PUDIERAN PRESENTARSE\n",
    "        print(f\"'{token.text}' -> {token.pos_} ({spacy.explain(token.pos_)}) -> {token.tag_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESO DE ANALISIS DE DEPENDENCIA SINTÁCTICA\n",
    "# token.text: El texto del token (palabra actual)\n",
    "# token.dep_: El tipo de dependencia gramatical (su función sintáctica en la oración: sujeto, objeto, raíz, etc.)\n",
    "# spacy.explain(token.dep_): Una breve explicación textual de esa dependencia\n",
    "# token.head.text: El término principal del que depende ese token (la \"cabeza sintáctica\")\n",
    "for token in doc:\n",
    "     if not token.is_space: # IGNORAMOS LOS ESPACIOS QUE PUDIERAN PRESENTARSE \n",
    "        print(f\"'{token.text}' -> {token.dep_} ({spacy.explain(token.dep_)}) -> '{token.head.text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESO DE VISUALIZACION DEL OBEJTO PROCESADO POR SPACY\n",
    "# displacy.render: función que dibuja una visualización del objeto doc (procesado por spaCy).\n",
    "# style='dep': indica que quieres ver el árbol de dependencias gramaticales (no entidades nombradas).\n",
    "# jupyter=True: le dice a spaCy que lo dibuje directamente dentro del notebook de Jupyter.\n",
    "# options={'distance': 120}: cambia la distancia horizontal entre palabras en el gráfico (para que sea más legible si la oración es larga).\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZACION DE ENTIDADES\n",
    "# Las entidades nombradas son cosas como: personas, lugares, organizaciones, fechas, cantidades, etc.\n",
    "# ent.text: el texto de la entidad (ej. \"España\")\n",
    "# ent.label_: la etiqueta de tipo de entidad (ej. LOC)\n",
    "# spacy.explain(ent.label_): una descripción en texto del tipo (ej. \"Geopolitical entity\")\n",
    "if doc.ents:\n",
    "    print(\"Entidades encontradas:\")\n",
    "    print(\"Texto de la Entidad -> Etiqueta (Tipo)\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\"'{ent.text}' -> {ent.label_} ({spacy.explain(ent.label_)})\")\n",
    "else:\n",
    "    print(\"No se encontraron entidades nombradas en este texto.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZACION DE ENTIDADES\n",
    "displacy.render(doc,style='ent',jupyter=True,options={'distance':200})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.- TERCER TEXTO A ANALIZAR (SPACY + WORDCLOUD + MATPLOTLIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTAMOS LA LIBRERIA QUE UTILIZAREMOS PARA HACER UN CONTEO DE PALABRAS\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINIMOS UN TEXTO A PROCESAR \n",
    "texto_ejemplo = \"\"\"\n",
    "Con el propósito de reforzar su estrategia de liderazgo en innovación tecnológica, China anunció que, a partir del 1 de septiembre de 2025, \n",
    "la enseñanza de inteligencia artificial (IA) será obligatoria para todos los estudiantes de entre 6 y 15 años. \n",
    "La medida se aplicará en todo el sistema educativo básico, abarcando tanto escuelas primarias como secundarias. \n",
    "Este nuevo enfoque pedagógico forma parte de un plan integral impulsado por el Ministerio de Educación chino, que busca dotar a las\n",
    "nuevas generaciones de herramientas para desenvolverse en un mundo cada vez más digitalizado. \n",
    "Según el esquema presentado, cada alumno recibirá al menos ocho horas anuales de formación en IA, distribuidas en función de su nivel escolar. \n",
    "Durante los primeros años, los niños aprenderán los conceptos fundamentales de la inteligencia artificial mediante juegos didácticos, actividades \n",
    "prácticas y entornos virtuales diseñados para despertar la curiosidad tecnológica.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAMOS LOS PRIMEROS 150 CARACTERES DEL TEXTO A PROCESAR\n",
    "print(f\"'{texto_ejemplo[:150]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDAMOS QUE ESTAMOS TRABAJANDO CON UNA VARIALBLE STRING (STR)\n",
    "print(type(texto_ejemplo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESAMOS EL TEXTO CON SPACY\n",
    "# nlp: Es el objeto del modelo (es_core_news_lg)\n",
    "# texto_ejemplo: Es un string de texto.\n",
    "# doc: Es el resultado del análisis. Un objeto tipo Doc de spaCy, que contiene tokens, etiquetas gramaticales, entidades nombradas, dependencias sintácticas, etc.\n",
    "doc = nlp(texto_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIRMAMOS QUE \"doc\" ES UN OBJETO SPACY\n",
    "print(type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAMOS EL CONTENIDO\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINIMOS UNA LISTA CON LAS \"PALABRAS CLAVES\" QUE FORMARÁN PARTE DE NUESTRO ANÁLISIS\n",
    "palabras_clave = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESO DE TOKENIZACION\n",
    "# RECORREMOS CON UN CICLO FOR EL TEXTO A PROCESAR CREANDO LA TOKENIZACIÓN DEL TEXTO EN CUESTION\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PROCESO DE TOKENIZACION Y LEMATIZACION\n",
    "# token.is_alpha: Verifica si el token contiene solo letras (sin números ni signos de puntuación).\n",
    "# not token.is_stop: Filtra las stopwords. Esto ayuda a quedarte solo con palabras que aportan contenido relevante.\n",
    "# token.lemma_: Extrae el lema del token, es decir, su forma canónica o base.\n",
    "# .lower(): Convierte el lema a minúsculas.\n",
    "# palabras_clave.append(...): Agrega la palabra limpia a la lista palabras_clave.\n",
    "for token in doc:\n",
    "    if token.is_alpha and not token.is_stop:\n",
    "      palabras_clave.append(token.lemma_.lower())\n",
    "print(f\"Se extrajeron {len(palabras_clave)} palabras clave (lemas, sin stop words).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAMOS LAS PALABRAS CLAVE QUE SE DETECTARON\n",
    "print(palabras_clave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAMOS LAS PRIMERAS 15 PALABRAS\n",
    "print(f\"EJEMPLO DE LAS PRIMERAS 15 PALABRAS: {palabras_clave[:15]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETERMINAMOS LA FRECUENCIA DE LAS PALABRAS CLAVE\n",
    "frecuencia_palabras = Counter(palabras_clave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frecuencia_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAMOS LA FRECUENCIA DE LAS PRIMERAS N PALABRAS\n",
    "N = 15\n",
    "palabras_mas_comunes = frecuencia_palabras.most_common(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECORREMOS LA LISTA PARA VISUALIZARLO EN FORMA MÁS CLARA\n",
    "for palabra, frecuencia in palabras_mas_comunes:\n",
    "    print(f\"- '{palabra}' : {frecuencia}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAMOS EL WORDCLOUD CON LAS \"PALABRAS MAS COMUNES\"\n",
    "\"\"\"\n",
    "cmap='gray'        # Escala de grises\n",
    "cmap='viridis'     # Gradiente suave (default en muchos casos)\n",
    "cmap='plasma'      # Tonos cálidos\n",
    "cmap='hot'         # Colores tipo fuego (calor)\n",
    "cmap='cool'        # Tonos fríos\n",
    "\"\"\"\n",
    "wordcloud_generator = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    # Paleta de colores\n",
    "    colormap='plasma', \n",
    "    # Mostrar máximo 50 palabras\n",
    "    max_words=50,     \n",
    "    # Ya filtramos stop words antes\n",
    "    stopwords=None,  \n",
    "    # Evitar que agrupe palabras (ej. \"dióxido carbono\")\n",
    "    collocations=False  \n",
    ").generate_from_frequencies(frecuencia_palabras) # <-- Usar las frecuencias calculadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAMOS EL GRÁFICO\n",
    "\"\"\"\n",
    "interpolation='nearest'     # Sin suavizado (cuadriculado)\n",
    "interpolation='bilinear'    # Suavizado suave (más bonito para nubes de palabras)\n",
    "interpolation='bicubic'     # Aún más suavizado\n",
    "interpolation='hamming'     # Otros métodos más específicos\n",
    "\"\"\"\n",
    "plt.figure(figsize=(10, 5)) # Tamaño de la figura donde se mostrará\n",
    "plt.imshow(wordcloud_generator, interpolation='bilinear') # Mostrar la imagen generada\n",
    "plt.axis(\"off\") # No mostrar los ejes X e Y\n",
    "plt.tight_layout(pad=0) # Ajustar para que no haya bordes extra\n",
    "plt.show() # Mostrar la ventana con la nube"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
